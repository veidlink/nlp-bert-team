{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsHpOpBV-2LJ"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjQgIe3k-2LK"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# В юпитер ноутбуке если вносишь изменения в .py откуда делаются импорты функций и классов, ноутбук прогоняет старые версии, не замечая изменений.\n",
        "# Эти импорты это исправляют"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oyifLBxn-2LM"
      },
      "outputs": [],
      "source": [
        "import pickle                  # Для загрузки словаря\n",
        "import numpy as np             # математические операции\n",
        "\n",
        "import torch                                            # фреймворк для машинного обучения и нейросетей\n",
        "import torch.nn as nn                                   # TensorDataset для создания датасета из Тензора\n",
        "\n",
        "from aux.rnn_preprocessing import (                         # Импортируем из собственного файла функции для препросессинга\n",
        "                                data_preprocessing,         # А также модель\n",
        "                                preprocess_single_string,\n",
        "                                predict_sentence,\n",
        "                                LSTMClassifier\n",
        "                                )\n",
        "\n",
        "from gensim.models import KeyedVectors # Чтобы прочитать сохраненные векторы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD__gdPD-2LN"
      },
      "source": [
        "Загружаю вектора сохраненные с коллаб, также загружаю словарь vocab_to_int "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JFudGloB-2LO"
      },
      "outputs": [],
      "source": [
        "wv = KeyedVectors.load(\"aux/wv.wordvectors\", mmap='r')\n",
        "\n",
        "with open('aux/vocab_to_int.txt', 'rb') as f:\n",
        "    vocab_to_int = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmfkWlIq-2LP"
      },
      "source": [
        "Создаю embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU0LmC3s-2LO",
        "outputId": "deeda83c-92b7-42f2-e8ad-a924ed4f0194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EMBEDDING MATRIX SHAPE = number of words x EMEDDING_DIM: (196906, 32)\n"
          ]
        }
      ],
      "source": [
        "# Создаем слой эмбеддинга\n",
        "# -  wv[word]  обращается к вектору слова  word  в модели Word2Vec\n",
        "# и присваивает его переменной  embedding_vector .\n",
        "\n",
        "VOCAB_SIZE = len(vocab_to_int) + 1\n",
        "EMBEDDING_DIM = 32\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in vocab_to_int.items():\n",
        "    try:\n",
        "        embedding_vector = wv[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except KeyError as e:\n",
        "        # print(f'word: {word}')\n",
        "        pass\n",
        "\n",
        "\n",
        "embedding_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix)) # from_pretrained потому что мы его сами тренировали\n",
        "print(f'EMBEDDING MATRIX SHAPE = number of words x EMEDDING_DIM: {embedding_matrix.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2x5iv15jC5fM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Импортирую из отдельного файла LSTM и веса, map_location='cpu', т.к. по иначе у меня выдавало ошибку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "VI9NelTn-2LQ",
        "outputId": "2d9bdca0-57b1-481d-9957-50fb803e8eba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# EMBEDDING_DIM уже указал при создании embedding_matrix\n",
        "HIDDEN_DIM = 32\n",
        "SEQ_LEN = 200\n",
        "model = LSTMClassifier(embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_DIM, embedding=embedding_layer).to(DEVICE)\n",
        "model.load_state_dict(torch.load('aux/LTSM_model_epoch_7.pt', map_location='cpu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n2kGPqW-2LR"
      },
      "source": [
        "Предсказываем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CEYMQIzi-2LR",
        "outputId": "8cfb2129-9bc3-4788-af83-ff720df97470"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEQ_LEN = 200\n",
        "\n",
        "pred = predict_sentence('Красивая, чистая больница, доктора добрые, в восторге', model, SEQ_LEN, vocab_to_int)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = predict_sentence('Некрасивая, грязная больница, доктора злые, в ужасе и печали', model, SEQ_LEN, vocab_to_int)\n",
        "pred"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
